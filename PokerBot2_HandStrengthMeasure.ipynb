{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import collections\n",
    "from typing import Iterable\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypokerengine.players import BasePokerPlayer\n",
    "from pypokerengine.api.emulator import Emulator\n",
    "from pypokerengine.utils.game_state_utils import restore_game_state\n",
    "from pypokerengine.utils.card_utils import estimate_hole_card_win_rate, gen_cards\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Program settings\n",
    "global DEBUG\n",
    "DEBUG = False\n",
    "global WATCH_GAME\n",
    "WATCH_GAME = True\n",
    "\n",
    "\n",
    "# Load saved model or create new\n",
    "global save_model_to_file\n",
    "global load_saved_model\n",
    "global num_saves\n",
    "global model_pathname\n",
    "save_model_to_file = False\n",
    "load_saved_model = False\n",
    "num_saves = 0\n",
    "model_pathname = 'pathname'\n",
    "\n",
    "# Model info\n",
    "global model_input_size\n",
    "model_input_size = 21\n",
    "model_output_size = 4\n",
    "MEMORY_SIZE = 10000\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "#Training Info\n",
    "NUM_EPISODES = 10000\n",
    "TARGET_LAG_FACTOR = 7500\n",
    "INITIAL_STACK = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep RL constrants\n",
    "gamma = 0.2 \n",
    "\n",
    "# Step length taken to update the estimation of Q(S, A)\n",
    "alpha = 1\n",
    "\n",
    "# Greedy policy\n",
    "# Probability of choosing any action at random (vs. action with highest Q value)\n",
    "epsilon = 0.1\n",
    "epsilon_min = 0.05\n",
    "epsilon_decay = 0.99\n",
    "\n",
    "\n",
    "# Target Model Ketchup\n",
    "target_n_val = 7500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear_QNet(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        self.fc1 = torch.nn.Linear(input_size, 64)\n",
    "        self.fc2 = torch.nn.Linear(64, 64)\n",
    "        self.fc3 = torch.nn.Linear(64, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "    \n",
    "    def save(self, file_name='model.pth'):\n",
    "        model_folder_path = './model'\n",
    "        if not os.path.exists(model_folder_path):\n",
    "            os.makedirs(model_folder_path)\n",
    "\n",
    "        file_name = os.path.join(model_folder_path, file_name)\n",
    "        torch.save(self.state_dict(), file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNetwork:\n",
    "    def __init__(self):\n",
    "\n",
    "        # model\n",
    "        self.model = Linear_QNet(model_input_size, model_output_size)\n",
    "        # set optimizer and loss functions for models\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=0.001)\n",
    "        self.criterion = nn.MSELoss()\n",
    "\n",
    "    def get_model(self):\n",
    "        return self.model\n",
    "    \n",
    "    def train_step(self, state, action, reward, next_state, done):\n",
    "        state = torch.tensor(state, dtype=torch.float32)\n",
    "        next_state = torch.tensor(next_state, dtype=torch.float32)\n",
    "        action = torch.tensor(action, dtype=torch.float32)\n",
    "        reward = torch.tensor(reward, dtype=torch.float32)\n",
    "\n",
    "        if len(state.shape) == 1:\n",
    "            state = torch.unsqueeze(state, 0)\n",
    "            next_state = torch.unsqueeze(next_state, 0)\n",
    "            action = torch.unsqueeze(action, 0)\n",
    "            reward = torch.unsqueeze(reward,0)\n",
    "            done = (done, )\n",
    "        \n",
    "        q_values = self.model.forward(state)\n",
    "        next_q_values = q_values.clone()\n",
    "        for idx in range(len(done)):\n",
    "            q_new = reward[idx]\n",
    "            if not done[idx]:\n",
    "                q_new = reward[idx] + self.gamma * torch.max(self.model(next_state[idx]))\n",
    "\n",
    "            next_q_values[idx][torch.argmax(action[idx]).item()] = q_new\n",
    "\n",
    "        loss = self.criterion(next_q_values, q_values)\n",
    "        \n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper methods\n",
    "def flatten(x):\n",
    "    if isinstance(x, Iterable):\n",
    "        return [a for i in x for a in flatten(i)]\n",
    "    else:\n",
    "        return [x]      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PokerAgent(BasePokerPlayer):\n",
    "\n",
    "    def __init__(self):\n",
    "        \n",
    "        # Initialize model\n",
    "        self.model = DQNetwork()       \n",
    "\n",
    "        # Experience replay\n",
    "        self.memory = collections.deque(maxlen = MEMORY_SIZE)\n",
    "        self.batch_size = BATCH_SIZE\n",
    "        self.first_move = True\n",
    "        self.last_action = [0] * model_output_size\n",
    "        self.last_state = [0] * model_input_size\n",
    "        self.curr_stack = INITIAL_STACK\n",
    "    \n",
    "    def select_action(self, state):\n",
    "        if random.uniform(0, 1) < epsilon:\n",
    "            return random.randint(0, model_output_size - 1)\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                state = torch.tensor(state, dtype=torch.float32).view(1, -1)\n",
    "                q_values = self.model.get_model().forward(state)\n",
    "                return torch.argmax(q_values).item()\n",
    "    \n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def train_short_mem(self, state, action, reward, next_state, done):\n",
    "        self.model.train_step (state, action, reward, next_state, done)\n",
    "\n",
    "    def train_long_mem(self):\n",
    "        print(\"Long training\")\n",
    "        sample = None\n",
    "        if len(self.memory) > BATCH_SIZE:\n",
    "            sample = random.sample(self.memory, BATCH_SIZE)\n",
    "        else:\n",
    "            sample = self.memory\n",
    "        states, actions, rewards, next_states, dones = zip(*sample)\n",
    "        self.model.train_step(states, actions, rewards, next_states, dones)\n",
    "        \n",
    "\n",
    "    def declare_action(self, valid_actions, hole_card, round_state):\n",
    "        # Prepare feature vector based on the game state\n",
    "        feature_vector = self._extract_features(hole_card, round_state)\n",
    "\n",
    "        if not self.first_move:\n",
    "            self.train_short_mem(self.last_state, self.last_action, 0, feature_vector, False)\n",
    "            self.remember(self.last_state, self.last_action, 0, feature_vector, False)\n",
    "\n",
    "        self.first_move = False\n",
    "\n",
    "        if DEBUG:\n",
    "            print(\"input size: \" + str(len(feature_vector)))\n",
    "            print(\"input shape: \" + str(feature_vector.shape))\n",
    "        \n",
    "        \n",
    "        # Use the model to predict the action\n",
    "        # action will be number 1-4\n",
    "        ## 1 -> fold\n",
    "        ## 2 -> call\n",
    "        ## 3 -> min raise\n",
    "        ## 4 -> max raise\n",
    "        action_num = self.select_action(feature_vector)\n",
    "\n",
    "        action_map = {0: 'fold', 1: 'call', 2: 'raise', 3: 'raise'}\n",
    "\n",
    "        action = action_map.get(action_num, 0)\n",
    "        amount = 0\n",
    "\n",
    "        #get call val\n",
    "        if action_num == 1:\n",
    "            amount = valid_actions[1]['amount']\n",
    "\n",
    "        # get min raise val\n",
    "        if action_num == 2:\n",
    "            amount = valid_actions[2]['amount']['min']\n",
    "        \n",
    "        # get max raise val\n",
    "        if action_num == 3:\n",
    "            amount = valid_actions[2]['amount']['min']\n",
    "        \n",
    "        self.last_action = [0, 0, 0, 0]\n",
    "        self.last_action[action_num] = 1\n",
    "        self.last_state = feature_vector\n",
    "        \n",
    "        return action, amount\n",
    "    \n",
    "    def receive_game_start_message(self, game_info):\n",
    "    \n",
    "        self.roudstart_stack = INITIAL_STACK\n",
    "    \n",
    "    def _extract_features(self, hole_card, round_state, win = None):\n",
    "\n",
    "        \n",
    "        #simulate hand against 10000 flops extracting hand strength estimate, unless round over\n",
    "        hand_strength = 0\n",
    "        if win != None:\n",
    "            if win:\n",
    "                hand_strength = 1000\n",
    "            else:\n",
    "                hand_strength = 0\n",
    "        else:\n",
    "            hand_strength = estimate_hole_card_win_rate(1000, 3, gen_cards(hole_card), gen_cards(round_state['community_card']))\n",
    "\n",
    "        # 8 Standard features\n",
    "        \n",
    "        standard_features = [\n",
    "            round_state['round_count'],\n",
    "            round_state['pot']['main']['amount'],\n",
    "            sum([side_pot['amount'] for side_pot in round_state['pot']['side']]),\n",
    "            round_state['dealer_btn'],\n",
    "            round_state['small_blind_pos'],\n",
    "            round_state['big_blind_pos'],\n",
    "            round_state['small_blind_amount'],\n",
    "            self._street_to_feature(round_state['street'])\n",
    "        ]\n",
    "\n",
    "        # 8 Action history features (2 {# raises, # calls} for each betting stage: preflop, flop, turn, river)\n",
    "        action_history_features = self._aggregate_action_histories(round_state['action_histories'])\n",
    "\n",
    "        # Combine all features into a single fixed-size feature vector of length 34\n",
    "        # Flatten the list of lists\n",
    "        features = flatten([hand_strength] + standard_features + action_history_features)\n",
    "        features = np.array(features)\n",
    "        features = features.reshape(1, -1)\n",
    "        return features\n",
    "    \n",
    "    # Not neccesarily useful\n",
    "    def receive_round_start_message(self, round_count, hole_card, seats):\n",
    "        for seat in seats:\n",
    "            if seat['uuid']==self.uuid:\n",
    "                self.roudstart_stack = seat['stack']\n",
    "        self.first_move = True\n",
    "\n",
    "\n",
    "    # Not neccesarily useful\n",
    "    def receive_street_start_message(self, street, round_state):\n",
    "        pass\n",
    "\n",
    "    def _street_to_feature(self, street):\n",
    "        # Convert street to a numerical feature\n",
    "        streets = {'preflop': 1, 'flop': 2, 'turn': 3, 'river': 4, 'showdown': 5}\n",
    "        return streets.get(street, 0)\n",
    "    \n",
    "\n",
    "\n",
    "    def _aggregate_action_histories(self, action_histories):\n",
    "        '''\n",
    "        # Aggregate action histories into a fixed-length vector\n",
    "        # Example: Count the number of raises, calls, etc.\n",
    "        raise_count = sum(1 for action in action_histories.get('preflop', []) if action['action'] == 'raise')\n",
    "        call_count = sum(1 for action in action_histories.get('preflop', []) if action['action'] == 'call')\n",
    "        # Add more aggregated features as needed\n",
    "        # Ensure the length of this vector is fixed\n",
    "        return [raise_count, call_count]\n",
    "        '''\n",
    "        \n",
    "        # Initialize counts\n",
    "        raise_count = [0, 0, 0, 0]  # Preflop, Flop, Turn, River\n",
    "        call_count = [0, 0, 0, 0]\n",
    "        fold_count = [0, 0, 0, 0]\n",
    "\n",
    "        # Define rounds\n",
    "        rounds = ['preflop', 'flop', 'turn', 'river']\n",
    "\n",
    "        # Count actions in each round\n",
    "        for i, round in enumerate(rounds):\n",
    "            for action in action_histories.get(round, []):\n",
    "                if action['action'] == 'raise':\n",
    "                    raise_count[i] += 1\n",
    "                elif action['action'] == 'call':\n",
    "                    call_count[i] += 1\n",
    "                elif action['action'] == 'fold':\n",
    "                    fold_count[i] += 1\n",
    "\n",
    "        # Flatten and return\n",
    "        return raise_count + call_count + fold_count\n",
    "\n",
    "    # Can incorporate player observation in model updated with each move\n",
    "    def receive_game_update_message(self, new_action, round_state):\n",
    "        pass\n",
    "    \n",
    "    def receive_round_result_message(self, winners, hand_info, round_state):\n",
    "        # Calculate net chip gain from round\n",
    "        reward = 0\n",
    "        win = False\n",
    "        for w in winners:\n",
    "            if w['uuid'] == self.uuid:\n",
    "                win = True\n",
    "        for player in round_state['seats']:\n",
    "            if player['uuid'] == self.uuid:\n",
    "                new_stack = player['stack']\n",
    "                reward = new_stack - self.curr_stack\n",
    "                self.curr_stack = new_stack\n",
    "        \n",
    "        final_state = self._extract_features(None, round_state, win)\n",
    "\n",
    "        #train model with reward as net chip gain\n",
    "        self.train_short_mem(self.last_state, self.last_action, reward, final_state, True)        \n",
    "        self.remember(self.last_state, self.last_action, reward, final_state, True)     \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'bool' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/williamobrien/pokerbot/PokerBot2_HandStrengthMeasure.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamobrien/pokerbot/PokerBot2_HandStrengthMeasure.ipynb#X11sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m config\u001b[39m.\u001b[39mregister_player(name \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mp3\u001b[39m\u001b[39m'\u001b[39m, algorithm\u001b[39m=\u001b[39mplayer3)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamobrien/pokerbot/PokerBot2_HandStrengthMeasure.ipynb#X11sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# play poker game \u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/williamobrien/pokerbot/PokerBot2_HandStrengthMeasure.ipynb#X11sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m game_result \u001b[39m=\u001b[39m start_poker(config, verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamobrien/pokerbot/PokerBot2_HandStrengthMeasure.ipynb#X11sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m player1\u001b[39m.\u001b[39mtrain_long_mem()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamobrien/pokerbot/PokerBot2_HandStrengthMeasure.ipynb#X11sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m player2\u001b[39m.\u001b[39mtrain_long_mem()\n",
      "File \u001b[0;32m~/anaconda3/envs/pkrenv1/lib/python3.11/site-packages/pypokerengine/api/game.py:14\u001b[0m, in \u001b[0;36mstart_poker\u001b[0;34m(config, verbose)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mfor\u001b[39;00m info \u001b[39min\u001b[39;00m config\u001b[39m.\u001b[39mplayers_info:\n\u001b[1;32m     13\u001b[0m     dealer\u001b[39m.\u001b[39mregister_player(info[\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m], info[\u001b[39m\"\u001b[39m\u001b[39malgorithm\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m---> 14\u001b[0m result_message \u001b[39m=\u001b[39m dealer\u001b[39m.\u001b[39mstart_game(config\u001b[39m.\u001b[39mmax_round)\n\u001b[1;32m     15\u001b[0m \u001b[39mreturn\u001b[39;00m _format_result(result_message)\n",
      "File \u001b[0;32m~/anaconda3/envs/pkrenv1/lib/python3.11/site-packages/pypokerengine/engine/dealer.py:39\u001b[0m, in \u001b[0;36mDealer.start_game\u001b[0;34m(self, max_round)\u001b[0m\n\u001b[1;32m     37\u001b[0m   table \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__exclude_short_of_money_players(table, ante, sb_amount)\n\u001b[1;32m     38\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__is_game_finished(table): \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m   table \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mplay_round(round_count, sb_amount, ante, table)\n\u001b[1;32m     40\u001b[0m   table\u001b[39m.\u001b[39mshift_dealer_btn()\n\u001b[1;32m     41\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__generate_game_result(max_round, table\u001b[39m.\u001b[39mseats)\n",
      "File \u001b[0;32m~/anaconda3/envs/pkrenv1/lib/python3.11/site-packages/pypokerengine/engine/dealer.py:48\u001b[0m, in \u001b[0;36mDealer.play_round\u001b[0;34m(self, round_count, blind_amount, ante, table)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__message_check(msgs, state[\u001b[39m\"\u001b[39m\u001b[39mstreet\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m     47\u001b[0m \u001b[39mif\u001b[39;00m state[\u001b[39m\"\u001b[39m\u001b[39mstreet\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m!=\u001b[39m Const\u001b[39m.\u001b[39mStreet\u001b[39m.\u001b[39mFINISHED:  \u001b[39m# continue the round\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m   action, bet_amount \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__publish_messages(msgs)\n\u001b[1;32m     49\u001b[0m   state, msgs \u001b[39m=\u001b[39m RoundManager\u001b[39m.\u001b[39mapply_action(state, action, bet_amount)\n\u001b[1;32m     50\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# finish the round after publish round result\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pkrenv1/lib/python3.11/site-packages/pypokerengine/engine/dealer.py:103\u001b[0m, in \u001b[0;36mDealer.__publish_messages\u001b[0;34m(self, msgs)\u001b[0m\n\u001b[1;32m    101\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmessage_handler\u001b[39m.\u001b[39mprocess_message(address, msg)\n\u001b[1;32m    102\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmessage_summarizer\u001b[39m.\u001b[39msummarize_messages(msgs)\n\u001b[0;32m--> 103\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmessage_handler\u001b[39m.\u001b[39mprocess_message(\u001b[39m*\u001b[39mmsgs[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/pkrenv1/lib/python3.11/site-packages/pypokerengine/engine/dealer.py:191\u001b[0m, in \u001b[0;36mMessageHandler.process_message\u001b[0;34m(self, address, msg)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[39mfor\u001b[39;00m receiver \u001b[39min\u001b[39;00m receivers:\n\u001b[1;32m    190\u001b[0m   \u001b[39mif\u001b[39;00m msg[\u001b[39m\"\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mask\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 191\u001b[0m     \u001b[39mreturn\u001b[39;00m receiver\u001b[39m.\u001b[39mrespond_to_ask(msg[\u001b[39m\"\u001b[39m\u001b[39mmessage\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    192\u001b[0m   \u001b[39melif\u001b[39;00m msg[\u001b[39m\"\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mnotification\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    193\u001b[0m     receiver\u001b[39m.\u001b[39mreceive_notification(msg[\u001b[39m\"\u001b[39m\u001b[39mmessage\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/pkrenv1/lib/python3.11/site-packages/pypokerengine/players.py:48\u001b[0m, in \u001b[0;36mBasePokerPlayer.respond_to_ask\u001b[0;34m(self, message)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Called from Dealer when ask message received from RoundManager\"\"\"\u001b[39;00m\n\u001b[1;32m     47\u001b[0m valid_actions, hole_card, round_state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__parse_ask_message(message)\n\u001b[0;32m---> 48\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdeclare_action(valid_actions, hole_card, round_state)\n",
      "\u001b[1;32m/Users/williamobrien/pokerbot/PokerBot2_HandStrengthMeasure.ipynb Cell 9\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamobrien/pokerbot/PokerBot2_HandStrengthMeasure.ipynb#X11sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m feature_vector \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_extract_features(hole_card, round_state)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamobrien/pokerbot/PokerBot2_HandStrengthMeasure.ipynb#X11sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfirst_move:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/williamobrien/pokerbot/PokerBot2_HandStrengthMeasure.ipynb#X11sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_short_mem(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlast_state, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlast_action, \u001b[39m0\u001b[39m, feature_vector, \u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamobrien/pokerbot/PokerBot2_HandStrengthMeasure.ipynb#X11sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mremember(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlast_state, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlast_action, \u001b[39m0\u001b[39m, feature_vector, \u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamobrien/pokerbot/PokerBot2_HandStrengthMeasure.ipynb#X11sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfirst_move \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;32m/Users/williamobrien/pokerbot/PokerBot2_HandStrengthMeasure.ipynb Cell 9\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamobrien/pokerbot/PokerBot2_HandStrengthMeasure.ipynb#X11sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_short_mem\u001b[39m(\u001b[39mself\u001b[39m, state, action, reward, next_state, done):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/williamobrien/pokerbot/PokerBot2_HandStrengthMeasure.ipynb#X11sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mtrain_step (state, action, reward, next_state, done)\n",
      "\u001b[1;32m/Users/williamobrien/pokerbot/PokerBot2_HandStrengthMeasure.ipynb Cell 9\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamobrien/pokerbot/PokerBot2_HandStrengthMeasure.ipynb#X11sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m q_values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mforward(state)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamobrien/pokerbot/PokerBot2_HandStrengthMeasure.ipynb#X11sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m next_q_values \u001b[39m=\u001b[39m q_values\u001b[39m.\u001b[39mclone()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/williamobrien/pokerbot/PokerBot2_HandStrengthMeasure.ipynb#X11sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(done)):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamobrien/pokerbot/PokerBot2_HandStrengthMeasure.ipynb#X11sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     q_new \u001b[39m=\u001b[39m reward[idx]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williamobrien/pokerbot/PokerBot2_HandStrengthMeasure.ipynb#X11sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m done[idx]:\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'bool' has no len()"
     ]
    }
   ],
   "source": [
    "from pypokerengine.api.game import setup_config, start_poker\n",
    "\n",
    "#creat models to train\n",
    "\n",
    "player1 = PokerAgent()\n",
    "player2 = PokerAgent()\n",
    "player3 = PokerAgent()\n",
    "\n",
    "for e in range(NUM_EPISODES):\n",
    "\n",
    "    # Declare game setup paramers\n",
    "    config = setup_config(max_round=100, initial_stack=INITIAL_STACK, small_blind_amount=5)\n",
    "    config.register_player(name = 'p1', algorithm=player1)\n",
    "    config.register_player(name = 'p2', algorithm=player2)\n",
    "    config.register_player(name = 'p3', algorithm=player3)\n",
    "\n",
    "    # play poker game \n",
    "    \n",
    "    game_result = start_poker(config, verbose=0)\n",
    "\n",
    "    player1.train_long_mem()\n",
    "    player2.train_long_mem()\n",
    "    player3.train_long_mem()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pkrenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "13cc0df5bbbf998b72edacc6b8887e6c4f34ef072e22ef9566e0b6f19315d46f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
