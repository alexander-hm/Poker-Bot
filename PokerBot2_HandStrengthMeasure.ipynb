{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import collections\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.layers import Dense, Flatten, Reshape, LeakyReLU\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from datetime import datetime\n",
    "import keras\n",
    "import keras.callbacks\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypokerengine.players import BasePokerPlayer\n",
    "from pypokerengine.api.emulator import Emulator\n",
    "from pypokerengine.utils.game_state_utils import restore_game_state\n",
    "import handcomparator \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Program settings\n",
    "global DEBUG\n",
    "DEBUG = False\n",
    "global WATCH_GAME\n",
    "WATCH_GAME = True\n",
    "\n",
    "# Reinforcement learning active\n",
    "global train_model\n",
    "train_model = True\n",
    "\n",
    "# Load saved model or create new\n",
    "global save_model_to_file\n",
    "global load_saved_model\n",
    "global num_saves\n",
    "global model_pathname\n",
    "save_model_to_file = False\n",
    "load_saved_model = False\n",
    "num_saves = 0\n",
    "model_pathname = 'pathname'\n",
    "\n",
    "# Model info\n",
    "global model_input_size\n",
    "model_input_size = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep RL constrants\n",
    "gamma = 0.2 \n",
    "\n",
    "# Step length taken to update the estimation of Q(S, A)\n",
    "alpha = 1\n",
    "\n",
    "# Greedy policy\n",
    "# Probability of choosing any action at random (vs. action with highest Q value)\n",
    "epsilon = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(128, activation='relu', input_shape=input_shape),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dense(3, activation='softmax')  # Assuming simple output (fold, call, or raise)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper methods\n",
    "def flatten(x):\n",
    "        if isinstance(x, collections.Iterable):\n",
    "            return [a for i in x for a in flatten(i)]\n",
    "        else:\n",
    "            return [x]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PokerBot(BasePokerPlayer):\n",
    "    \n",
    "    # TODO: Read some saved state of the model to allow reinforcement learning over time\n",
    "    def __init__(self):\n",
    "        # Initialize model\n",
    "        if load_saved_model and os.path.isfile(model_pathname):\n",
    "            load_model()\n",
    "        else:\n",
    "            self.model = create_model((model_input_size,))  # Input shape, adjust based on features\n",
    "        # Save game states and actions in input output matrices for Q learning\n",
    "        self.x = [] # States\n",
    "        self.Y = [] # Actions\n",
    "        self.Q = [] # Q Scores (chip rewards)\n",
    "    \n",
    "    # TODO: Look at Emulator implementation to make the model work with reinforcement learning\n",
    "    # Make an action based on the model output\n",
    "    def declare_action(self, valid_actions, hole_card, round_state):\n",
    "        # Prepare feature vector based on the game state\n",
    "        feature_vector = self._extract_features(hole_card, round_state)\n",
    "        if DEBUG:\n",
    "            print(\"input size: \" + str(len(feature_vector)))\n",
    "            print(\"input shape: \" + str(feature_vector.shape))\n",
    "        \n",
    "        \n",
    "        # Use the model to predict the action\n",
    "        action_probs = self.model.predict(feature_vector).flatten()\n",
    "\n",
    "        # If raising invalid move restrict valid moves to fold and call\n",
    "        if valid_actions[2][\"amount\"][\"max\"] == -1:\n",
    "            action_probs = action_probs[:2]\n",
    "\n",
    "        if random.random() < epsilon:\n",
    "            outcome = random.randint(0, len(action_probs)-1)\n",
    "        else:\n",
    "            outcome = np.argmax(action_probs)\n",
    "        \n",
    "        if DEBUG:\n",
    "            print(\"action_probs length: \" + str(len(action_probs)))\n",
    "            print(action_probs)\n",
    "            print(\"action argmax: \" + str(outcome))\n",
    "        \n",
    "        action_info = valid_actions[outcome]\n",
    "        action = action_info['action']\n",
    "        if outcome == 2:\n",
    "            # Scale raise to the confidence of the model\n",
    "            amount = action_info['amount']['min'] + math.floor((action_info['amount']['max'] - action_info['amount']['min']) * action_probs[outcome])\n",
    "            if DEBUG:\n",
    "                print(valid_actions)\n",
    "                print(str((action_info['amount']['max'] - action_info['amount']['min']) * action_probs[outcome]))\n",
    "        else:\n",
    "            amount = action_info['amount']\n",
    "        \n",
    "        # Update Q learning input, output (observation, action)\n",
    "        # np.append(self.x, feature_vector, axis=1)\n",
    "        # np.append(self.Y, [action, amount], axis=1)\n",
    "        self.x.append(feature_vector)\n",
    "        self.Y.append([action, amount])\n",
    "        \n",
    "        return action, amount\n",
    "    \n",
    "    # Setup Emulator object by registering game information\n",
    "    def receive_game_start_message(self, game_info):\n",
    "        return\n",
    "        \n",
    "        # Emulator skeleton code\n",
    "        player_num = game_info['player_num']\n",
    "        max_round = game_info['rule']['max_round']\n",
    "        small_blind_amount = game_info['rule']['small_blind_amount']\n",
    "        ante_amount = game_info['rule']['ante']\n",
    "        blind_structure = game_info['rule']['blind_structure']\n",
    "        \n",
    "        self.emulator = Emulator()\n",
    "        self.emulator.set_game_rule(player_num, max_round, small_blind_amount, ante_amount)\n",
    "        self.emulator.set_blind_structure(blind_structure)\n",
    "        \n",
    "        # Register algorithm of each player which used in the simulation.\n",
    "        for player_info in game_info['seats']['players']:\n",
    "            self.emulator.register_player(player_info['uuid'], PokerBot())\n",
    "\n",
    "    # Not neccesarily useful\n",
    "    def receive_round_start_message(self, round_count, hole_card, seats):\n",
    "        # Reset Round info for Q learning\n",
    "        # NOTE: Only for debugging purposes. Optimal practices may vary\n",
    "        self.x = []\n",
    "        self.Y = []\n",
    "        self.Q = []\n",
    "        pass\n",
    "\n",
    "    # Not neccesarily useful\n",
    "    def receive_street_start_message(self, street, round_state):\n",
    "        pass\n",
    "\n",
    "    # Can incorporate player observation in model updated with each move\n",
    "    def receive_game_update_message(self, new_action, round_state):\n",
    "        pass\n",
    "    \n",
    "    # Update model with each round result\n",
    "    def receive_round_result_message(self, winners, hand_info, round_state):\n",
    "        # Calculate net chip gain from round\n",
    "        if winners[0]['uuid'] == self.uuid:\n",
    "            # Player won the round\n",
    "            print(\"Player \", winners[0]['uuid'], \" won the round\")\n",
    "            gain = 1\n",
    "        else:\n",
    "            gain = -1\n",
    "        stake = 0                    \n",
    "        streets = ['preflop', 'flop', 'turn', 'river']\n",
    "        for street in streets:\n",
    "            if street in round_state['action_histories']:\n",
    "                for action in round_state['action_histories'][street]:\n",
    "                    # print(action)\n",
    "                    # if action['action'] == 'ANTE' or 'SMALLBLIND' or 'BIGBLIND' or 'FOLD':\n",
    "                    #     # Do nothing for now\n",
    "                    #     print(action['action'])\n",
    "                    #     pass\n",
    "                    # else:\n",
    "                    #     stake += action['paid']\n",
    "                    #     print(\"Q stake\", stake)\n",
    "                    #     self.Q.append(stake * gain)\n",
    "                    if action['uuid'] == self.uuid:\n",
    "                        if action['action'] == 'CALL' or action['action'] == 'RAISE':\n",
    "                            stake += action['paid']\n",
    "                            self.Q.append(stake * gain)\n",
    "                        elif action['action'] == 'FOLD':\n",
    "                            self.Q.append(0)\n",
    "        \n",
    "        if WATCH_GAME:\n",
    "            print(\"Round actions: player \" + self.uuid)\n",
    "            print(\"Y: \", self.Y)\n",
    "            print(\"Q: \", self.Q)\n",
    "        \n",
    "        # Update model\n",
    "        if train_model:\n",
    "            # Update model with round results\n",
    "            pass\n",
    "        if save_model_to_file:\n",
    "            # Save model to file\n",
    "            save_model()\n",
    "        pass\n",
    "    \n",
    "    # Additional methods\n",
    "    \n",
    "    # Produce a feature vector of length 17\n",
    "    def _extract_features(self, hole_card, round_state):\n",
    "        \n",
    "        #simulate hand against 10000 flops extracting hand strength estimate\n",
    "        \n",
    "        hand_strength = self._hand_strength_sim(hole_card, round_state['community_card'])\n",
    "\n",
    "        # 8 Standard features\n",
    "        standard_features = [\n",
    "            round_state['round_count'],\n",
    "            round_state['pot']['main']['amount'],\n",
    "            sum([side_pot['amount'] for side_pot in round_state['pot']['side']]),\n",
    "            round_state['dealer_btn'],\n",
    "            round_state['small_blind_pos'],\n",
    "            round_state['big_blind_pos'],\n",
    "            round_state['small_blind_amount'],\n",
    "            self._street_to_feature(round_state['street'])\n",
    "        ]\n",
    "\n",
    "        # 8 Action history features (2 {# raises, # calls} for each betting stage: preflop, flop, turn, river)\n",
    "        action_history_features = self._aggregate_action_histories(round_state['action_histories'])\n",
    "\n",
    "        # Combine all features into a single fixed-size feature vector of length 34\n",
    "        # Flatten the list of lists\n",
    "        features = flatten([hand_strength] + standard_features + action_history_features)\n",
    "        features = np.array(features)\n",
    "        features = features.reshape(1, -1)\n",
    "        return features\n",
    "    \n",
    "    def _hand_strength_sim(self, cards, board):\n",
    "        deck = Deck()\n",
    "        deck.shuffle()\n",
    "        my_hand = []\n",
    "        board = []\n",
    "        for c in cards:\n",
    "            print(c)\n",
    "            card = Card(c[0], c[-1])\n",
    "            my_hand.append(card)\n",
    "        for b in board:\n",
    "            card = Card(b[0], b[-1])\n",
    "            my_hand.append(card)\n",
    "        deck.remove(my_hand+board)\n",
    "        board_size = len(board)\n",
    "        score = 0\n",
    "        for i in range(1000):\n",
    "            draw = random.sample(deck.get_allcards, 7-board_size)\n",
    "            opp_hand = board + draw\n",
    "            my_hand = my_hand + draw[2:]\n",
    "            if handcomparator.find_winner(my_hand, opp_hand):\n",
    "                score += 1\n",
    "        return score/10000\n",
    "    \n",
    "    def _street_to_feature(self, street):\n",
    "        # Convert street to a numerical feature\n",
    "        streets = {'preflop': 1, 'flop': 2, 'turn': 3, 'river': 4, 'showdown': 5}\n",
    "        return streets.get(street, 0)\n",
    "\n",
    "    def _aggregate_action_histories(self, action_histories):\n",
    "        '''\n",
    "        # Aggregate action histories into a fixed-length vector\n",
    "        # Example: Count the number of raises, calls, etc.\n",
    "        raise_count = sum(1 for action in action_histories.get('preflop', []) if action['action'] == 'raise')\n",
    "        call_count = sum(1 for action in action_histories.get('preflop', []) if action['action'] == 'call')\n",
    "        # Add more aggregated features as needed\n",
    "        # Ensure the length of this vector is fixed\n",
    "        return [raise_count, call_count]\n",
    "        '''\n",
    "        \n",
    "        # Initialize counts\n",
    "        raise_count = [0, 0, 0, 0]  # Preflop, Flop, Turn, River\n",
    "        call_count = [0, 0, 0, 0]\n",
    "        fold_count = [0, 0, 0, 0]\n",
    "\n",
    "        # Define rounds\n",
    "        rounds = ['preflop', 'flop', 'turn', 'river']\n",
    "\n",
    "        # Count actions in each round\n",
    "        for i, round in enumerate(rounds):\n",
    "            for action in action_histories.get(round, []):\n",
    "                if action['action'] == 'raise':\n",
    "                    raise_count[i] += 1\n",
    "                elif action['action'] == 'call':\n",
    "                    call_count[i] += 1\n",
    "                elif action['action'] == 'fold':\n",
    "                    fold_count[i] += 1\n",
    "\n",
    "        # Flatten and return\n",
    "        return raise_count + call_count + fold_count\n",
    "    \n",
    "    \n",
    "    def save_model(self):\n",
    "        self.model.save(model_pathname + '_V' + num_saves)\n",
    "    \n",
    "    def load_model(self):\n",
    "        self.model = load_model(model_pathname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started the round 1\n",
      "Street \"preflop\" started. (community card = [])\n",
      "SJ\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'J'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[101], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m config\u001b[39m.\u001b[39mregister_player(name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mp2\u001b[39m\u001b[39m\"\u001b[39m, algorithm\u001b[39m=\u001b[39mPokerBot())\n\u001b[1;32m      7\u001b[0m config\u001b[39m.\u001b[39mregister_player(name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mp3\u001b[39m\u001b[39m\"\u001b[39m, algorithm\u001b[39m=\u001b[39mPokerBot())\n\u001b[0;32m----> 8\u001b[0m game_result \u001b[39m=\u001b[39m start_poker(config, verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/pkrenv/lib/python3.9/site-packages/pypokerengine/api/game.py:14\u001b[0m, in \u001b[0;36mstart_poker\u001b[0;34m(config, verbose)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mfor\u001b[39;00m info \u001b[39min\u001b[39;00m config\u001b[39m.\u001b[39mplayers_info:\n\u001b[1;32m     13\u001b[0m     dealer\u001b[39m.\u001b[39mregister_player(info[\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m], info[\u001b[39m\"\u001b[39m\u001b[39malgorithm\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m---> 14\u001b[0m result_message \u001b[39m=\u001b[39m dealer\u001b[39m.\u001b[39;49mstart_game(config\u001b[39m.\u001b[39;49mmax_round)\n\u001b[1;32m     15\u001b[0m \u001b[39mreturn\u001b[39;00m _format_result(result_message)\n",
      "File \u001b[0;32m~/anaconda3/envs/pkrenv/lib/python3.9/site-packages/pypokerengine/engine/dealer.py:39\u001b[0m, in \u001b[0;36mDealer.start_game\u001b[0;34m(self, max_round)\u001b[0m\n\u001b[1;32m     37\u001b[0m   table \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__exclude_short_of_money_players(table, ante, sb_amount)\n\u001b[1;32m     38\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__is_game_finished(table): \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m   table \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mplay_round(round_count, sb_amount, ante, table)\n\u001b[1;32m     40\u001b[0m   table\u001b[39m.\u001b[39mshift_dealer_btn()\n\u001b[1;32m     41\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__generate_game_result(max_round, table\u001b[39m.\u001b[39mseats)\n",
      "File \u001b[0;32m~/anaconda3/envs/pkrenv/lib/python3.9/site-packages/pypokerengine/engine/dealer.py:48\u001b[0m, in \u001b[0;36mDealer.play_round\u001b[0;34m(self, round_count, blind_amount, ante, table)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__message_check(msgs, state[\u001b[39m\"\u001b[39m\u001b[39mstreet\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m     47\u001b[0m \u001b[39mif\u001b[39;00m state[\u001b[39m\"\u001b[39m\u001b[39mstreet\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m!=\u001b[39m Const\u001b[39m.\u001b[39mStreet\u001b[39m.\u001b[39mFINISHED:  \u001b[39m# continue the round\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m   action, bet_amount \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__publish_messages(msgs)\n\u001b[1;32m     49\u001b[0m   state, msgs \u001b[39m=\u001b[39m RoundManager\u001b[39m.\u001b[39mapply_action(state, action, bet_amount)\n\u001b[1;32m     50\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# finish the round after publish round result\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pkrenv/lib/python3.9/site-packages/pypokerengine/engine/dealer.py:103\u001b[0m, in \u001b[0;36mDealer.__publish_messages\u001b[0;34m(self, msgs)\u001b[0m\n\u001b[1;32m    101\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmessage_handler\u001b[39m.\u001b[39mprocess_message(address, msg)\n\u001b[1;32m    102\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmessage_summarizer\u001b[39m.\u001b[39msummarize_messages(msgs)\n\u001b[0;32m--> 103\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmessage_handler\u001b[39m.\u001b[39;49mprocess_message(\u001b[39m*\u001b[39;49mmsgs[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m])\n",
      "File \u001b[0;32m~/anaconda3/envs/pkrenv/lib/python3.9/site-packages/pypokerengine/engine/dealer.py:191\u001b[0m, in \u001b[0;36mMessageHandler.process_message\u001b[0;34m(self, address, msg)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[39mfor\u001b[39;00m receiver \u001b[39min\u001b[39;00m receivers:\n\u001b[1;32m    190\u001b[0m   \u001b[39mif\u001b[39;00m msg[\u001b[39m\"\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mask\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 191\u001b[0m     \u001b[39mreturn\u001b[39;00m receiver\u001b[39m.\u001b[39;49mrespond_to_ask(msg[\u001b[39m\"\u001b[39;49m\u001b[39mmessage\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m    192\u001b[0m   \u001b[39melif\u001b[39;00m msg[\u001b[39m\"\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mnotification\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    193\u001b[0m     receiver\u001b[39m.\u001b[39mreceive_notification(msg[\u001b[39m\"\u001b[39m\u001b[39mmessage\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/pkrenv/lib/python3.9/site-packages/pypokerengine/players.py:48\u001b[0m, in \u001b[0;36mBasePokerPlayer.respond_to_ask\u001b[0;34m(self, message)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Called from Dealer when ask message received from RoundManager\"\"\"\u001b[39;00m\n\u001b[1;32m     47\u001b[0m valid_actions, hole_card, round_state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__parse_ask_message(message)\n\u001b[0;32m---> 48\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdeclare_action(valid_actions, hole_card, round_state)\n",
      "Cell \u001b[0;32mIn[100], line 19\u001b[0m, in \u001b[0;36mPokerBot.declare_action\u001b[0;34m(self, valid_actions, hole_card, round_state)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdeclare_action\u001b[39m(\u001b[39mself\u001b[39m, valid_actions, hole_card, round_state):\n\u001b[1;32m     18\u001b[0m     \u001b[39m# Prepare feature vector based on the game state\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m     feature_vector \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_extract_features(hole_card, round_state)\n\u001b[1;32m     20\u001b[0m     \u001b[39mif\u001b[39;00m DEBUG:\n\u001b[1;32m     21\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39minput size: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mlen\u001b[39m(feature_vector)))\n",
      "Cell \u001b[0;32mIn[100], line 148\u001b[0m, in \u001b[0;36mPokerBot._extract_features\u001b[0;34m(self, hole_card, round_state)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_extract_features\u001b[39m(\u001b[39mself\u001b[39m, hole_card, round_state):\n\u001b[1;32m    145\u001b[0m     \n\u001b[1;32m    146\u001b[0m     \u001b[39m#simulate hand against 10000 flops extracting hand strength estimate\u001b[39;00m\n\u001b[0;32m--> 148\u001b[0m     hand_strength \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_hand_strength_sim(hole_card, round_state[\u001b[39m'\u001b[39;49m\u001b[39mcommunity_card\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m    150\u001b[0m     \u001b[39m# 8 Standard features\u001b[39;00m\n\u001b[1;32m    151\u001b[0m     standard_features \u001b[39m=\u001b[39m [\n\u001b[1;32m    152\u001b[0m         round_state[\u001b[39m'\u001b[39m\u001b[39mround_count\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m    153\u001b[0m         round_state[\u001b[39m'\u001b[39m\u001b[39mpot\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mmain\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mamount\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_street_to_feature(round_state[\u001b[39m'\u001b[39m\u001b[39mstreet\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m    160\u001b[0m     ]\n",
      "Cell \u001b[0;32mIn[100], line 179\u001b[0m, in \u001b[0;36mPokerBot._hand_strength_sim\u001b[0;34m(self, cards, board)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m cards:\n\u001b[1;32m    178\u001b[0m     \u001b[39mprint\u001b[39m(c)\n\u001b[0;32m--> 179\u001b[0m     card \u001b[39m=\u001b[39m Card(c[\u001b[39m0\u001b[39;49m], c[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m])\n\u001b[1;32m    180\u001b[0m     my_hand\u001b[39m.\u001b[39mappend(card)\n\u001b[1;32m    181\u001b[0m \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m board:\n",
      "File \u001b[0;32m/var/folders/0b/crrplqjx4hz81s7jwj6gcx540000gn/T/ipykernel_8562/136125160.py:6\u001b[0m, in \u001b[0;36mCard.__init__\u001b[0;34m(self, suit, rank)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msuit\u001b[39m=\u001b[39msuit\n\u001b[1;32m      5\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrank\u001b[39m=\u001b[39mrank\n\u001b[0;32m----> 6\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalue\u001b[39m=\u001b[39mvalues[rank]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'J'"
     ]
    }
   ],
   "source": [
    "from pypokerengine.api.game import setup_config, start_poker\n",
    "\n",
    "# Declare game setup paramers\n",
    "config = setup_config(max_round=10, initial_stack=100, small_blind_amount=5)\n",
    "config.register_player(name=\"p1\", algorithm=PokerBot())\n",
    "config.register_player(name=\"p2\", algorithm=PokerBot())\n",
    "config.register_player(name=\"p3\", algorithm=PokerBot())\n",
    "game_result = start_poker(config, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pkrenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "13cc0df5bbbf998b72edacc6b8887e6c4f34ef072e22ef9566e0b6f19315d46f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
